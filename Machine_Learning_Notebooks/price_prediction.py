# -*- coding: utf-8 -*-
"""Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MYDa2CKK_fbnkPiQBCnP02QzPIoJuU5d
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.figure_factory as ff
import plotly.express as px
import warnings
warnings.filterwarnings('ignore')

cotton = pd.read_csv('/content/drive/MyDrive/Colab work/Cotton.csv')
gram = pd.read_csv('/content/drive/MyDrive/Colab work/Gram.csv')
jute = pd.read_csv('/content/drive/MyDrive/Colab work/Jute.csv')
maize = pd.read_csv('/content/drive/MyDrive/Colab work/Maize.csv')
moong = pd.read_csv('/content/drive/MyDrive/Colab work/Moong.csv')
wheat = pd.read_csv('/content/drive/MyDrive/Colab work/Wheat.csv')
coconut = pd.read_csv('/content/drive/MyDrive/Colab work/coconut.csv')

cotton.columns

cotton.insert(4, 'crop_name', 'cotton')
gram.insert(4, 'crop_name', 'gram')
jute.insert(4, 'crop_name', 'jute')
maize.insert(4, 'crop_name', 'maize')
moong.insert(4, 'crop_name', 'moong')
wheat.insert(4, 'crop_name', 'wheat')
coconut.insert(4, 'crop_name', 'coconut')

cotton.head()

df = pd.concat([cotton, gram, jute, maize, moong, wheat, coconut],ignore_index=True)

df.head() #WPI = wholesale_price_index

cotton.size

df.Year.unique()

df.head(n=407)

"""

```
# from functools import reduce
data_frames = [cotton, gram, jute, maize, moong, wheat,coconut]
df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['crop_name'],
                                            how='outer'), data_frames)

# if you want to fill the values that don't exist in the lines of merged dataframe simply fill with required strings as

df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['crop_name'],
                                            how='outer'), data_frames).fillna('void')
                                            pd.DataFrame.to_csv(df_merged, 'merged.txt', sep=',', na_rep='.', index=False)
```

"""

df.corr()

df.isnull().sum()

"""# **encoding**

```
# def ordinal_encoder2015(df, feats): 
    for feat in feats:    
        feat_val = list(1+np.arange(df[feat].nunique()))
        feat_key = list(df[feat].sort_values().unique())
        feat_dict = dict(zip(feat_key, feat_val))
        df[feat] = df[feat].map(feat_dict)
    return df
```
"""

from sklearn.preprocessing import LabelEncoder

df['crop_name']= LabelEncoder().fit_transform(df.crop_name)
df['rainfall_new']= LabelEncoder().fit_transform(df.Rainfall)
df['WPI_NEW']= LabelEncoder().fit_transform(df.WPI)

df.dtypes

df.head()

"""# **model**"""

from sklearn.model_selection import train_test_split
#from sklearn.metrics.ConfusionMatrixDisplay import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestRegressor

x = df.drop(['WPI','Rainfall'], axis=1)
y = df.WPI_NEW

#x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.250,random_state=250)
x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=50)

rfr = RandomForestRegressor(random_state = 1, max_depth = 7, max_features = 'log2', n_estimators = 15)
rfr.fit(x_train,y_train)

rfr.score(x_test, y_test)